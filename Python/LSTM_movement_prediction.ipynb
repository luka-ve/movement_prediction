{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import h5py\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find data files recursively from root folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"D:/Coding/Thesis/Data/STFT Output/**/*.h5\"\n",
    "data_files = glob.glob(data_path, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "config['EEG_window_length_in_ms'] = 30000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we configure the output layer of the LSTM:\n",
    "\n",
    "\n",
    "`delta_time_k` predicts the delta time to the next $k^{th}$ tap.\n",
    "\n",
    "`tap_count_times_p` predicts the *number of taps* within the next $p$ seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['delta_time_k'] = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "config['tap_count_times_p'] = np.array([0.5, 1, 5, 10, 50, 100, 500])\n",
    "\n",
    "config['EEG_sampling_rate'] = 1000\n",
    "config['stft_stride'] = 32\n",
    "config['sampling_rate_after_stft'] = config['EEG_sampling_rate'] / config['stft_stride']\n",
    "config['sample_length_after_stft'] = 1000 / config['sampling_rate_after_stft']\n",
    "\n",
    "config['tap_count_times_in_samples'] = np.multiply(config['tap_count_times_p'], config['EEG_sampling_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ParticipantData class\n",
    "The ParticipantData class contains and acts on participant data. It knows about the structure of the h5 files and can return random windows of EEG activity and taps, i.e., training data.\n",
    "\n",
    "The stft data in the h5 files is 3-dimensional:\n",
    "1. EEG channel\n",
    "2. EEG timeseries\n",
    "3. STFT frequency bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticipantData:\n",
    "    def __init__(self, data_files):\n",
    "        self.data_file_paths = data_files\n",
    "        \n",
    "        self.open_h5_files()\n",
    "        \n",
    "        self._generate_group_idx()\n",
    "    \n",
    "    \n",
    "    def _generate_group_idx(self):\n",
    "        self.sessions = [list(participant.keys()) for participant in self.data_files_open]\n",
    "\n",
    "        #windows = [list(participant[session].keys()) for participant in data_files_open for session in list(participant.keys())]\n",
    "        self.windows = []\n",
    "        for participant in self.data_files_open:\n",
    "            for session in list(participant.keys()):\n",
    "                self.windows.append(list(participant[session].keys()))\n",
    "    \n",
    "    \n",
    "    def open_h5_files(self):\n",
    "        self.data_files_open = [h5py.File(f, 'r') for f in self.data_file_paths]\n",
    "    \n",
    "    \n",
    "    def close_h5_files(self):\n",
    "        for f in self.data_files_open:\n",
    "            f.close()\n",
    "        \n",
    "        self.data_files_open = []\n",
    "    \n",
    "    \n",
    "    def get_random_EEG_window(self, window_length):\n",
    "        ppt = random.choice(self.data_files_open)        \n",
    "        session = random.choice(list(ppt.keys()))\n",
    "        activity_window = random.choice(list(ppt[session].keys()))\n",
    "        \n",
    "        window_length_in_samples = np.ceil(window_length / config['stft_stride']).astype(np.int)\n",
    "        \n",
    "        window_end_idx = np.random.randint(window_length_in_samples, ppt[session][activity_window]['stft'].shape[1])       \n",
    "        window_idx_stft = np.arange(window_end_idx - window_length_in_samples, window_end_idx, dtype=np.int)        \n",
    "        \n",
    "        input_data = np.array(ppt[session][activity_window]['stft'][:, window_idx_stft, :])\n",
    "        \n",
    "        window_end_idx_tap_adjusted = np.ceil(np.array(window_end_idx) * config['sampling_rate_after_stft']).astype(np.int)\n",
    "        \n",
    "        output_data = self.get_taps_in_window(np.array(ppt[session][activity_window]['taps'], dtype=np.int), window_end_idx_tap_adjusted)\n",
    "                \n",
    "        return(input_data, output_data)\n",
    "    \n",
    "    \n",
    "    def get_taps_in_window(self, taps, window_end):      \n",
    "        tap_deltas = self.get_delta_taps(taps, window_end)\n",
    "        \n",
    "        future_tap_n = self.get_n_future_taps(taps, window_end)\n",
    "        \n",
    "        result = np.concatenate((tap_deltas, future_tap_n))\n",
    "\n",
    "        return(result)\n",
    "    \n",
    "    \n",
    "    def get_delta_taps(self, taps, window_idx):\n",
    "        n_k = len(config['delta_time_k'])\n",
    "        \n",
    "        next_kth_taps = taps[taps > window_idx][:n_k]\n",
    "        \n",
    "        # Ensure that if not enough taps were found the array is padded with 0s.\n",
    "        # This only occurs \n",
    "        if len(next_kth_taps) < n_k:\n",
    "            next_kth_taps = np.concatenate((next_kth_taps, np.zeros(n_k - len(next_kth_taps))))\n",
    "        \n",
    "        tap_deltas = next_kth_taps - window_idx\n",
    "        \n",
    "        return(tap_deltas)\n",
    "            \n",
    "    \n",
    "    def get_n_future_taps(self, taps, window_idx):\n",
    "        n_future_taps = np.zeros(len(config['tap_count_times_in_samples']))\n",
    "        \n",
    "        for p_idx, p in enumerate(config['tap_count_times_in_samples']):\n",
    "            n_future_taps[p_idx] = len(\n",
    "                taps[\n",
    "                    (taps > window_idx) &\n",
    "                    (taps <= (window_idx + p))\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        return(n_future_taps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ppt_data = ParticipantData(data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data into memory\n",
    "\n",
    "Instead of loading data from the h5 file when we need it, we load all the data of a single participant into memory (because it fits and it's easier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(h5_files):\n",
    "    EEG, taps = [], []\n",
    "    \n",
    "    # Makse sure that if a single file is passed in, it is put into a list\n",
    "    if type(h5_files) != 'list':\n",
    "        h5_files = [h5_files]\n",
    "    \n",
    "    for f in h5_files:\n",
    "        with h5py.File(f, 'r') as f_open:        \n",
    "            for session in list(f_open.keys()):\n",
    "                for activity_window in list(f_open[session].keys()):\n",
    "                    EEG.append(np.array(f_open[session][activity_window]['stft']))\n",
    "                    taps.append(np.array(f_open[session][activity_window]['stft']))\n",
    "        \n",
    "    return (EEG, taps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%time stft, taps = load_data(data_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing ParticipantData class with class inherited from `tf.keras.utils.Sequence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(keras.utils.Sequence):\n",
    "    def __init__(self, x, y, window_length=30000, batch_size=32, n_samples=2000, shuffle=True):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.window_length = window_length\n",
    "        self.batch_size = batch_size\n",
    "        self.n_samples = n_samples\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.subset_probabilities = self._get_subset_probabilites(x)\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        [win.shape[1] for win in x]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index=0):\n",
    "        X = []\n",
    "        Y = []\n",
    "        \n",
    "        for batch in range(self.batch_size):\n",
    "            if self.shuffle:\n",
    "                # Pick random activity window\n",
    "                # Since subsets are of different length and contain different amounts of data,\n",
    "                # we need to adjust the probability of each subset being picked to its length.\n",
    "                subset_idx = np.random.choice(len(self.x), p = self.subset_probabilities)\n",
    "\n",
    "                # Pick random EEG window\n",
    "                window_length_in_samples = np.ceil(self.window_length / config['stft_stride']).astype(np.int)\n",
    "\n",
    "                window_end_idx = np.random.randint(window_length_in_samples, self.x[subset_idx].shape[1])       \n",
    "                window_idx_stft = np.arange(window_end_idx - window_length_in_samples, window_end_idx, dtype=np.int)        \n",
    "\n",
    "                input_data = np.array(self.x[subset_idx][:, window_idx_stft, :])\n",
    "                \n",
    "                # Get appropriate tap info        \n",
    "                window_end_idx_tap_adjusted = np.ceil(np.array(window_end_idx) * config['sampling_rate_after_stft']).astype(np.int)\n",
    "\n",
    "                output_data = self.get_taps_in_window(self.y[subset_idx], window_end_idx_tap_adjusted)\n",
    "            else:\n",
    "                subset_idx = 0 # TODO Change this as soon as I know how __getitem__ is called\n",
    "                \n",
    "                # EEG data\n",
    "                window_length_in_samples = np.ceil(self.window_length / config['stft_stride']).astype(np.int)\n",
    "                window_idx_stft = np.arange(index - window_length_in_samples, index, dtype=np.int)\n",
    "                input_data = np.array(self.x[subset_idx][:, window_idx_stft, :])\n",
    "                \n",
    "                # Tap data\n",
    "                window_end_idx_tap_adjusted = np.ceil(np.array(index) * config['sampling_rate_after_stft']).astype(np.int)\n",
    "                output_data = self.get_taps_in_window(self.y[subset_idx], window_end_idx_tap_adjusted)\n",
    "            \n",
    "            X.append(input_data)\n",
    "            Y.append(output_data)\n",
    "                \n",
    "        return X, Y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "    \n",
    "    def _get_subset_probabilites(self, x):\n",
    "        lengths = np.array([win.shape[1] for win in x])\n",
    "        \n",
    "        return lengths / sum(lengths)\n",
    "        \n",
    "    \n",
    "    def get_taps_in_window(self, taps, window_end):      \n",
    "        tap_deltas = self.get_delta_taps(taps, window_end)\n",
    "        \n",
    "        future_tap_n = self.get_n_future_taps(taps, window_end)\n",
    "        \n",
    "        result = np.concatenate((tap_deltas, future_tap_n))\n",
    "\n",
    "        return result \n",
    "    \n",
    "    \n",
    "    def get_delta_taps(self, taps, window_idx):\n",
    "        n_k = len(config['delta_time_k'])\n",
    "        \n",
    "        next_kth_taps = taps[taps > window_idx][:n_k]\n",
    "        \n",
    "        # Ensure that if not enough taps were found the array is padded with 0s.\n",
    "        # This only occurs \n",
    "        if len(next_kth_taps) < n_k:\n",
    "            next_kth_taps = np.concatenate((next_kth_taps, np.zeros(n_k - len(next_kth_taps))))\n",
    "        \n",
    "        tap_deltas = next_kth_taps - window_idx\n",
    "        \n",
    "        return tap_deltas\n",
    "            \n",
    "    \n",
    "    def get_n_future_taps(self, taps, window_idx):\n",
    "        n_future_taps = np.zeros(len(config['tap_count_times_in_samples']))\n",
    "        \n",
    "        for p_idx, p in enumerate(config['tap_count_times_in_samples']):\n",
    "            n_future_taps[p_idx] = len(\n",
    "                taps[\n",
    "                    (taps > window_idx) &\n",
    "                    (taps <= (window_idx + p))\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        return n_future_taps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining the in- and outputs of the LSTM\n",
    "Next, we check the sizes that are returned by our data generation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt1 = DataLoader(stft, taps, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         324 function calls in 19.331 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "        8   17.552    2.194   17.552    2.194 <ipython-input-38-d7219537c5ad>:91(get_n_future_taps)\n",
       "        8    1.661    0.208    1.661    0.208 <ipython-input-38-d7219537c5ad>:76(get_delta_taps)\n",
       "        1    0.070    0.070   19.321   19.321 <ipython-input-38-d7219537c5ad>:17(__getitem__)\n",
       "       16    0.036    0.002    0.036    0.002 {built-in method numpy.array}\n",
       "        1    0.010    0.010   19.331   19.331 <string>:1(<module>)\n",
       "        8    0.001    0.000    0.001    0.000 {method 'choice' of 'numpy.random.mtrand.RandomState' objects}\n",
       "       16    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
       "        8    0.000    0.000    0.000    0.000 {method 'randint' of 'numpy.random.mtrand.RandomState' objects}\n",
       "        8    0.000    0.000   19.214    2.402 <ipython-input-38-d7219537c5ad>:66(get_taps_in_window)\n",
       "        8    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\n",
       "       16    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\n",
       "       16    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.generic' objects}\n",
       "       80    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
       "       16    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(concatenate)\n",
       "        1    0.000    0.000   19.331   19.331 {built-in method builtins.exec}\n",
       "       16    0.000    0.000    0.000    0.000 getlimits.py:366(__new__)\n",
       "       16    0.000    0.000    0.000    0.000 numerictypes.py:286(issubclass_)\n",
       "        8    0.000    0.000    0.000    0.000 numerictypes.py:360(issubdtype)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
       "       16    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
       "       16    0.000    0.000    0.000    0.000 multiarray.py:143(concatenate)\n",
       "       16    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%prun my_batch_x, my_batch_y = ppt1[0] # get a random batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And do a sanity check on the content of the generated target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer dimensions: (64, 938, 32)\n",
      "Output layer dimensions: (17,)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "print(f'Input layer dimensions: {my_batch_x[0].shape}')\n",
    "print(f'Output layer dimensions: {my_batch_y[0].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input layer\n",
    "The ParticipantData class generates an input information that is $64 \\times 938 \\times 32$ in size. Since the second dimension is the temporal information, the LSTM's input layer has the a size of $64 \\times 32 = 2048$ and takes a window of 938 samples at a time.\n",
    "\n",
    "This conversion from window length in ms to window length in samples can be calculated by the following formula:\n",
    "\n",
    "$$\n",
    "\\bigl\\lceil\n",
    "\\frac{\\frac{\\text{T}}{1000} \\text{Fs}}\n",
    "{\\text{R}}\n",
    "\\bigr\\rceil\n",
    "$$\n",
    "\n",
    ", where $T$ is the window length in ms, $Fs$ is the original sampling rate, and $R$ is the hopsize of the STFT.\n",
    "\n",
    "## Output layer\n",
    "The ParticipantData class also generates training output. The output layer has a length of 17. It is composed of the $\\Delta t$ to the next $k$ steps in ms, as well as the number of taps within the next $p$ seconds. Which and how many $k$ and $p$ are predicted is defined in the config dictionary at the top of the file. The size of the output layer is defined as $|K| + |P|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "# Add input layer\n",
    "model.add(layers.LSTM(\n",
    "    128,\n",
    "    input_shape = ()\n",
    "))\n",
    "model.add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close h5 files again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt_data.close_h5_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
